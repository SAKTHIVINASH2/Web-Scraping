# ğŸ•¸ï¸ Web-Scraping

This repository demonstrates two different approaches to web scraping in Python:

1. **Static Scraping** â€“ Using standard libraries like `requests` and `BeautifulSoup` to parse HTML and extract data embedded in JavaScript variables.
2. **Spider-Based Scraping** â€“ Using Scrapy spiders to crawl pages and extract structured data embedded inside `<script>` tags.

---

## ğŸ“ Project Structure

```
Web-Scraping/
â”œâ”€â”€ static_scraping/     # Static HTML scraping with JS data extraction
â”œâ”€â”€ spider_scraping/     # Scrapy spider for JS-embedded JSON extraction
â”œâ”€â”€ requirements.txt     # List of dependencies
â”œâ”€â”€ LICENSE              # MIT License
â””â”€â”€ README.md            # Project overview
```

---

## ğŸ§° Technologies Used

- `requests` â€“ for sending HTTP requests (in static scraping)
- `beautifulsoup4` â€“ for HTML parsing
- `re` â€“ for regex matching `<script>` tags
- `json` â€“ to parse JavaScript-embedded JSON
- `scrapy` â€“ for spider-based web scraping

---

## ğŸ” Scraping Methods

### 1. ğŸ“¦ Static Scraping (`static_scraping/`)

**Technique:**  
`HTML Parsing + Embedded JavaScript Data Extraction`

- Loads the page with `requests`
- Parses the HTML using `BeautifulSoup`
- Locates a `<script>` tag with `window.PAGE_MODEL = {...}` JavaScript object
- Extracts and converts the embedded JSON into structured Python data

ğŸ‘‰ Best for websites where JSON data is embedded directly in the HTML source.

---

### 2. ğŸ•·ï¸ Spider-Based Scraping (`spider_scraping/`)

**Technique:**  
`Spider-Based HTML Parsing with Embedded JavaScript Data Extraction`

- Uses Scrapy to crawl pages
- Extracts JavaScript-embedded data in `<script>` tags
- Processes and stores it using Scrapy's item pipeline or file output

ğŸ‘‰ Ideal for scraping multiple pages or when you want scalable crawling logic.

---

## ğŸ“¦ Installation

1. Clone this repository:
   ```bash
   git clone https://github.com/SAKTHIVINASH2/Web-Scraping.git
   cd Web-Scraping
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

---

## â–¶ï¸ Usage

### Static Scraping
Navigate to the `static_scraping` directory and run the script:

```bash
cd static_scraping
python scrape_static.py
```

### Spider-Based Scraping (using Scrapy)
Navigate to the `spider_scraping` directory and run:

```bash
cd spider_scraping
scrapy crawl property_spider
```

---

## ğŸ“ License

This project is licensed under the MIT License. See the [LICENSE](./LICENSE) file for details.

---

## ğŸ™Œ Author

- [Sakthivinash](https://github.com/SAKTHIVINASH2)

---

## â­ï¸ Give a Star!

If you found this repository useful, consider giving it a â­ to support the project!
